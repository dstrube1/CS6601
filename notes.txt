conda create --name ai_env python=3.7 -y
conda env remove -n ai_env

conda activate ai_env
conda deactivate

jupyter notebook

git clone --bare https://github.gatech.edu/omscs6601/assignment_6.git
cd assignment_6.git
git push --mirror https://github.gatech.edu/dstrube3/CS6601_Assignment6
cd ..
rm -rf assignment_6.git
git clone https://github.gatech.edu/dstrube3/CS6601_Assignment6
cd CS6601_Assignment6
git remote add upstream https://github.gatech.edu/omscs6601/assignment_6.git
(pull from the original repo :)
git pull upstream master 
(push to my repo :)
git push origin master
(if this fails:
open the repo in Github Desktop
push
)

https://github.gatech.edu/omscs6601/assignment_5
https://github.gatech.edu/dstrube3/CS6601_Assignment5
https://github.gatech.edu/omscs6601/assignment_6
https://github.gatech.edu/dstrube3/CS6601_Assignment6


https://stackoverflow.com/questions/62898911/how-to-downgrade-python-version-from-3-8-to-3-7-mac#62899833
pyenv install --list
pyenv install 3.7.12
pyenv global 3.7.12
python -V

What is a problem?
Initial State s
Actions on s: Actions(s) -> {a1, a2, a3...}
Result(s,a) -> new state s'
function GoalTest(s) -> T or F if state is where we want to be
function PathCost which takes a path / sequence of state / action transitions, and returns a number: 
PathCost(s + a -> s + a -> s...) -> n, cost of the path
StepCost(s, a, s') -> n, cost of that action

State space: all possible options
frontier: farthest paths that have been explored
BFS, DFS, Uniform cost, Cheapest first, A*

Frontier:
priorityqueue / Hashset

Explored: Hashset

Simulated annealing:
Random restart
inefficient, but lots of samples
	taboo search:
keep track of places tried
restart when get to the same place
	stage algorithm
-keep list of local maxima
-predict next random restart based on unexplored
step size could be too small or too large
start with large step size and get smaller
high temp = more random
cooling = low randomness
T is the simulated temperature at time _t_, which reduces from a high value at the beginning to near zero eventually.
ΔE is the change in energy going from current to next.
[8]
[2] = "8 choose 2" = (8!) / ((8 - 2)! * 2!)

tree nodes (n) at depth d: 
branching factor b=2: 2^(d+1)-1
b=3: (3^(d+1)-1)/2
b=k: (k^(d+1)-1)/(k-1)
iterative deepening nodes (IDN):
1st:1
next: n tree nodes + prev IDN

git push --mirror https://github.gatech.edu/dstrube3/CS6601_Assignment2

depth-first tree-like search takes time proportional to the number of states
 has memory complexity of only O(bm), where b is the branching factor
  and m is the maximum depth of the tree

depth-limited search:
time complexity is O(b^l) and the space complexity is O(b*l) (l = depth limit)

Iterative deepening search:
 memory requirements: O(bd) when there is a solution, or O(bm) on finite state spaces with no solution
 optimal for problems where all actions have the same cost
 complete on finite acyclic state spaces
 complete on any finite state space when we check nodes for cycles all the way up the path
 time complexity is O(b^d ) when there is a solution, or O(b^m) when there is none
 
bidirectional search
 b^(d/2) + b^(d/2)

consistency: A heuristic h(n) is consistent if, for every node n and every successor n′ of n generated by an action a, we have:
h(n) ≤ c(n,a,n′)+h(n′).

admissibility: an admissible heuristic is one that never overestimates the cost to reach a goal. (An admissible heuristic is therefore optimistic.)

Every consistent heuristic is admissible (but not vice versa)

Bayes Network:
nodes correspond to events / random variables
children arcs have probable (non determined) effects on parent
Joint probability:
	If 
1- probability of cancer, P(C) = 0.01
2- P(!C) = 0.99
3- Probability of positive test result, given cancer (dependence), P(+|C) = 0.9
4- P(-|C) = 0.1
5- P(+|!C) = 0.2
6- P(-|!C) = 0.8
	Then
A: Joint probability of positive test AND cancer (independent), P(+,C) = 
P(C) * P(+|C) = 0.01 * 0.9 = 0.009
B: P(-,C) = P(C) * P(-|C) = 0.01 * 0.1 = 0.001
C: P(+, !C) = P(!C) * P(+|!C) = 0.99 * 0.2 = 0.198
D: P(-, !C) = P(!C) * P(-|!C) = 0.99 * 0.8 = 0.792
E: P(C | +) = P(+,C) / (P(+,C) + P(+,!C))
0.009 / (0.009 + 0.198) = 0.009 / 0.207 =~ 0.043

Bayes Rule:
A: the variable we care about, the cause(s), e.g., cancer
B: the evidence, e.g., cancer test result
P(A|B) = (P(B|A) * P(A)) / P(B)
P(B|A): the likelihood: given that we knew the cause, what would be the probability of the evidence observed
P(A): the prior
P(B): the marginal likelihood, probability of the evidence, = 
P(A|B): the posterior
P(B) expanded using the Theorem of Total Probability: 
	Sum of all probabilities of B given A = a (P(B|A=a)) * probability of A = a (P(A=a))
Inverse of A is simple:
P(!A|B) = (P(B|!A) * P(!A)) / P(B)
P(A|B) + P(!A|B) = 1
	If we use pseudo probabilities that are non normalized: 
P'(A|B) = P(B|A) * P(A)
P'(!A|B) = P(B|!A) * P(!A)
	and we have normalizer eta
	then:
P(A|B) = eta * P'(A|B)
P(!A|B) = eta * P'(!A|B)
eta = (P'(A|B) + P'(!A|B))^-1 = 1 / (P'(A|B) + P'(!A|B))

What is the probability that test 2 is positive given that test 1 is positive?:
P(T2 = + | T1 = +) = 
["T2 = +" => +2]
P(+2 | +1,C) * P(C | +1) + P(+2 | +1, !C) * P(!C | +1) {from Theorem of total probability}

temperature gauge correct: 0.95
not temperature gauge correct: 0.05

faulty temperature gauge: 0.2
not faulty temperature gauge: 0.8

true = hot
false = normal

alarm faulty: 0.15
not alarm faulty: 0.85

temperature hot = 0.2
not temperature hot = 0.8

P(alarm) = 
P(faulty alarm) = 0.15 / 0.85

Machine Learning:
if data set has 100 bits of data, 10 will be reserve, leaving 90 for training and testing (T&T)
20% of T&T = testing = 18
=> (90)
	(18)
	: "90 choose 18 possibilities" > 10^18
LOOCV: leave-one-out cross validation
if dataset has 10, train on 8, test on 2 => (10)(2) = 45
(n)(r) = n! / (r!*(n-r))!
https://www.calculatorsoup.com/calculators/discretemathematics/combinations.php
Gaussian formula: 
p(x) = 1/(s * sqrt(2 * pi)) * e^ -((x - u)^2 / 2 * (s^2))
	where u = mean and s^2 = variance, s = standard deviation

