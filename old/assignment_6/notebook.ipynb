{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Hidden Markov Models\n",
    "\n",
    "## Submission\n",
    "All submissions will be via Gradescope. If you're completing this assignment in Jupyter Notebook, you must run the `notebook2script.py` file to export your work to a python file. To generate your submission file, run the command \n",
    "\n",
    "`python notebook2script.py submission`\n",
    "\n",
    "and your file will be created under the `submission` directory.\n",
    "\n",
    "Upload the resulting `submission.py` file to the Assignment 6 assignment on Gradescope for feedback.\n",
    "\n",
    "#### IMPORTANT: A total of 10 submissions is allowed for this assignment. Please use your submissions carefully and do not submit until you have thoroughly tested your code locally.\n",
    "\n",
    "#### If you're at 9 submissions, use your tenth and last submission wisely. The submission marked as ‘Active’ in Gradescope will be the submission counted towards your grade. \n",
    "\n",
    "Please also submit your submission.py to Canvas as backup.\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The goal of this assignment is to demonstrate the power of probabalistic models. You will build a word recognizer for American Sign Language (ASL) video sequences. In particular, this project employs hidden Markov models (HMM's) to analyze a series of measurements taken from videos of American Sign Language (ASL) collected for research (see the [RWTH-BOSTON-104 Database](http://www-i6.informatik.rwth-aachen.de/~dreuw/database-rwth-boston-104.php)).\n",
    "\n",
    "In each video, an ASL signer is signing a meaningful sentence. In a typical ASL recognition system, you observe the XY coordinates of the speaker's left hand, right hand, and nose for every frame. The following diagram shows how the positions of the left hand (Red), right hand (Blue), and nose (Green) change over time in video number #66. Saturation of colors represents time elapsed.\n",
    "\n",
    "<img src=\"./demo/hands_nose_position.png\" alt=\"hands nose position\">\n",
    "\n",
    "In this assignment, for the sake of simplicity, you will only use the Y-coordinates of each hand to construct your HMM. In Part 1 you will build a one dimensional model, recognizing words based only on a series of right-hand Y coordinates; in Part 2 you will go multidimensional and utilize both hands. At this point, you will have two observed coordinates at each time step (frame) representing right hand & left hand Y positions.\n",
    "\n",
    "The words you will be recognizing are \"BUY\", \"HOUSE\", and \"CAR\". These individual signs can be seen in the sign phrases from our dataset:\n",
    "\n",
    "![](demo/buy_house_slow.gif) \n",
    "\n",
    "<p style=\"text-align:center; font-weight:bold\"> JOHN CAN BUY HOUSE </p> \n",
    "\n",
    "![](demo/buy_car_slow.gif) \n",
    "\n",
    "<p style=\"text-align:center;  font-weight:bold\"> JOHN BUY CAR [FUTURE] </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1a: Encoding the HMM\n",
    "_[15 Points]_\n",
    "\n",
    "Follow the method taught on Udacity **Lecture 8: 29. HMM Training** to determine following values for each word:\n",
    "1. the transition probabilities of each state\n",
    "2. the mean & standard deviation of emission Gaussian distribution of each state\n",
    "\n",
    "Use the training samples from the table below. Provide the transition, prior, and emission probabilities parameters for all three words with **accuracy to 3 decimal digits**.\n",
    "\n",
    "Round the values to 3 decimal places thoughout entire assignment:\n",
    "- 0.1 stays 0.1 or 0.100\n",
    "- 0.1234 rounds to 0.123\n",
    "- 0.2345 rounds to 0.235\n",
    "- 0.3456 rounds to 0.346\n",
    "- 0.0123 rounds to 0.012\n",
    "- 0.0125 rounds to 0.013\n",
    "\n",
    "Those values can be hardcoded in your program. Don't use round() from python.\n",
    "\n",
    "Word | Frames | Observed sequence | Initial State1 | Initial State2 | Initial State3\n",
    "--- | --- | --- | --- | --- | --- \n",
    "BUY | 6 | 36, 44, 52, 56, 49, 44 | 36, 44 | 52, 56 | 49, 44\n",
    "BUY | 8 | 42, 46, 54, 62, 68, 65, 60, 56 | 42, 46, 54 | 62, 68, 65 | 60, 56\n",
    "BUY | 10 | 42, 40, 41, 43, 52, 55, 59, 60, 55, 47 | 42, 40, 41|43, 52, 55|59, 60, 55, 47\n",
    "CAR | 10 | 47, 39, 32, 34, 36, 42, 42, 42, 34, 25|47, 39, 32|34, 36, 42|42, 42, 34, 25\n",
    "CAR | 9 | 35, 35, 43, 46, 52, 52, 56, 49, 45|35, 35, 43|46, 52, 52|56, 49, 45\n",
    "CAR | 8 | 28, 35, 46, 46, 48, 43, 43, 40|28, 35, 46|46, 48, 43|43, 40\n",
    "HOUSE| 15 | 37, 36, 32, 26, 26, 25, 23, 22, 21, 39, 48, 60, 70, 74, 77|37, 36, 32, 26, 26|25, 23, 22, 21, 39|48, 60, 70, 74, 77\n",
    "HOUSE| 15 | 50, 50, 49, 47, 39, 39, 38, 38, 50, 56, 61, 67, 67, 67, 67|50, 50, 49, 47, 39|39, 38, 38, 50, 56|61, 67, 67, 67, 67\n",
    "HOUSE| 16 | 45, 43, 44, 43, 40, 35, 36, 37, 39, 45, 60, 68, 66, 72, 72, 75|45, 43, 44, 43, 40|35, 36, 37, 39, 45|60, 68, 66, 72, 72, 75\n",
    "\n",
    "As shown in the diagram below, each one of the three words (BUY, CAR, and HOUSE) has exactly **THREE hidden states** in its HMM. All words have equal probability of occuring. Modify the prior accordingly. All words must start from State 1 and can only transit to the next state or stay in the current one as shown below:\n",
    "\n",
    "<img src=\"part_1_a_probs.png\">\n",
    "\n",
    "### _Training sequences need to have 3 hidden states no matter what!_\n",
    "If you follow the procedure on the Udacity lecture video, you might encounter a situation where a hidden state is **_squeezed_** out by an adjacent state. In that situation, always keep at least one observation for that hidden state.\n",
    "\n",
    "Example:\n",
    "Assume you've reached a stage where the following is true: \n",
    "- State 1 has mean=53 & std=6\n",
    "- State 2 has mean=37 & std=9\n",
    "- State 3 has mean=70 & std=8\n",
    "\n",
    "The next training sample has the following observed sequence:\n",
    "\n",
    "`45 45 34 | 30 30 25 36 52 | 62 69 74` \n",
    "\n",
    "and you are trying to adjust the location of state boundary between State 1 & 2. You first move it 1 step to the left since 34 is closer to State 2, and then you realize that 45 is still closer to State 2. If you follow the same routine, you will end up with no obvervation for State 1. In order to prevent this from happening, you have to stop at the last \"45\" and as a result leave the boundary as \n",
    "\n",
    "`45 | 45 34 30 30 25 36 52 | 62 69 74`\n",
    "\n",
    "Now you meet the '3 hidden states per sample' requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmm_submission_test as tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def part_1_a():\n",
    "    \"\"\"Provide probabilities for the word HMMs outlined below.\n",
    "    Word BUY, CAR, and HOUSE.\n",
    "    Review Udacity Lesson 8 - Video #29. HMM Training\n",
    "    Returns:\n",
    "        tuple() of\n",
    "        (prior probabilities for all states for word BUY,\n",
    "         transition probabilities between states for word BUY,\n",
    "         emission parameters tuple(mean, std) for all states for word BUY,\n",
    "         prior probabilities for all states for word CAR,\n",
    "         transition probabilities between states for word CAR,\n",
    "         emission parameters tuple(mean, std) for all states for word CAR,\n",
    "         prior probabilities for all states for word HOUSE,\n",
    "         transition probabilities between states for word HOUSE,\n",
    "         emission parameters tuple(mean, std) for all states for word HOUSE,)\n",
    "        Sample Format (not complete):\n",
    "        (\n",
    "            {'B1': prob_of_starting_in_B1, 'B2': prob_of_starting_in_B2, ...},\n",
    "            {'B1': {'B1': prob_of_transition_from_B1_to_B1,\n",
    "                    'B2': prob_of_transition_from_B1_to_B2,\n",
    "                    'B3': prob_of_transition_from_B1_to_B3,\n",
    "                    'Bend': prob_of_transition_from_B1_to_Bend},\n",
    "             'B2': {...}, ...},\n",
    "            {'B1': tuple(mean_of_B1, standard_deviation_of_B1),\n",
    "             'B2': tuple(mean_of_B2, standard_deviation_of_B2), ...},\n",
    "            {'C1': prob_of_starting_in_C1, 'C2': prob_of_starting_in_C2, ...},\n",
    "            {'C1': {'C1': prob_of_transition_from_C1_to_C1,\n",
    "                    'C2': prob_of_transition_from_C1_to_C2,\n",
    "                    'C3': prob_of_transition_from_C1_to_C3,\n",
    "                    'Cend': prob_of_transition_from_C1_to_Cend},\n",
    "             'C2': {...}, ...}\n",
    "            {'C1': tuple(mean_of_C1, standard_deviation_of_C1),\n",
    "             'C2': tuple(mean_of_C2, standard_deviation_of_C2), ...}\n",
    "            {'H1': prob_of_starting_in_H1, 'H2': prob_of_starting_in_H2, ...},\n",
    "            {'H1': {'H1': prob_of_transition_from_H1_to_H1,\n",
    "                    'H2': prob_of_transition_from_H1_to_H2,\n",
    "                    'H3': prob_of_transition_from_H1_to_H3,\n",
    "                    'Hend': prob_of_transition_from_H1_to_Hend},\n",
    "             'H2': {...}, ...}\n",
    "            {'H1': tuple(mean_of_H1, standard_deviation_of_H1),\n",
    "             'H2': tuple(mean_of_H2, standard_deviation_of_H2), ...}\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: complete this function.\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    \"\"\"Word BUY\"\"\"\n",
    "    b_prior_probs = {\n",
    "        'B1': 0.,\n",
    "        'B2': 0.,\n",
    "        'B3': 0.,\n",
    "        'Bend': 0.,\n",
    "    }\n",
    "    b_transition_probs = {\n",
    "        'B1': {'B1': 0., 'B2': 0., 'B3': 0., 'Bend': 0.},\n",
    "        'B2': {'B1': 0., 'B2': 0., 'B3': 0., 'Bend': 0.},\n",
    "        'B3': {'B1': 0., 'B2': 0., 'B3': 0., 'Bend': 0.},\n",
    "        'Bend': {'B1': 0., 'B2': 0., 'B3': 0., 'Bend': 0.},\n",
    "    }\n",
    "    # Parameters for end state is not required\n",
    "    b_emission_paras = {\n",
    "        'B1': (None, None),\n",
    "        'B2': (None, None),\n",
    "        'B3': (None, None),\n",
    "        'Bend': (None, None)\n",
    "    }\n",
    "\n",
    "    \"\"\"Word CAR\"\"\"\n",
    "    c_prior_probs = {\n",
    "        'C1': 0.,\n",
    "        'C2': 0.,\n",
    "        'C3': 0.,\n",
    "        'Cend': 0.,\n",
    "    }\n",
    "    c_transition_probs = {\n",
    "        'C1': {'C1': 0., 'C2': 0., 'C3': 0., 'Cend': 0.},\n",
    "        'C2': {'C1': 0., 'C2': 0., 'C3': 0., 'Cend': 0.},\n",
    "        'C3': {'C1': 0., 'C2': 0., 'C3': 0., 'Cend': 0.},\n",
    "        'Cend': {'C1': 0., 'C2': 0., 'C3': 0., 'Cend': 0.},\n",
    "    }\n",
    "    # Parameters for end state is not required\n",
    "    c_emission_paras = {\n",
    "        'C1': (None, None),\n",
    "        'C2': (None, None),\n",
    "        'C3': (None, None),\n",
    "        'Cend': (None, None)\n",
    "    }\n",
    "\n",
    "    \"\"\"Word HOUSE\"\"\"\n",
    "    h_prior_probs = {\n",
    "        'H1': 0.,\n",
    "        'H2': 0.,\n",
    "        'H3': 0.,\n",
    "        'Hend': 0.,\n",
    "    }\n",
    "    # Probability of a state changing to another state.\n",
    "    h_transition_probs = {\n",
    "        'H1': {'H1': 0., 'H2': 0., 'H3': 0., 'Hend': 0.},\n",
    "        'H2': {'H1': 0., 'H2': 0., 'H3': 0., 'Hend': 0.},\n",
    "        'H3': {'H1': 0., 'H2': 0., 'H3': 0., 'Hend': 0.},\n",
    "        'Hend': {'H1': 0., 'H2': 0., 'H3': 0., 'Hend': 0.},\n",
    "    }\n",
    "    # Parameters for end state is not required\n",
    "    h_emission_paras = {\n",
    "        'H1': (None, None),\n",
    "        'H2': (None, None),\n",
    "        'H3': (None, None),\n",
    "        'Hend': (None, None)\n",
    "    }\n",
    "\n",
    "    return (b_prior_probs, b_transition_probs, b_emission_paras,\n",
    "            c_prior_probs, c_transition_probs, c_emission_paras,\n",
    "            h_prior_probs, h_transition_probs, h_emission_paras,)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.TestPart1a().test_prior(part_1_a)\n",
    "tests.TestPart1a().test_b_emission(part_1_a)\n",
    "tests.TestPart1a().test_c_emission(part_1_a)\n",
    "tests.TestPart1a().test_h_emission(part_1_a)\n",
    "tests.TestPart1a().test_b_transition(part_1_a)\n",
    "tests.TestPart1a().test_c_transition(part_1_a)\n",
    "tests.TestPart1a().test_h_transition(part_1_a)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1b: Creating the Viterbi Trellis\n",
    "_[40 Points]_\n",
    "\n",
    "The goal here will be to use the HMM derived from Part 1a (states, prior probabilities, transition probabilities, and parameters of emission distribution) to build a viterbi trellis.  When provided with an evidence vector (list of observed right-hand Y coordinates), the function will return the most likely sequence of states that generated the evidence and the probabilty of that sequence being correct.\n",
    "\n",
    "For example, an evidence vector [36, 44, 52, 53, 49, 44] should output a sequence ['B1', ... 'B2', ... 'B3']\n",
    "\n",
    "If no sequence can be found, the algorithm should return one of the following tuples:\n",
    "`(None, 0)` (null),  `([], 0)` (empty list) or  `(['C1', 'C1', ... 'C1'],0)` (Or all being the first state of that letter)\n",
    "\n",
    "\"No sequence can be found\" means the probability reaches 0 midway. If you find an incomplete sequence with some probability, output that sequence with its probability. \n",
    "\n",
    "#### Functions to complete:\n",
    "1. `viterbi()`\n",
    "\n",
    "#### Hint:\n",
    "In order to reconstruct your most-likely path after running Viterbi, you'll need to keep track of a back-pointer at each state, which directs you to that state's most-likely predecessor.\n",
    "\n",
    "You are asked to use the provided function `gaussian_prob` to compute  emission probabilities. Although in real work, you have to convert the probability to log-base in order to prevent digit underflow, in this assignment, we will only test your function against a rather short sequence of observations, so **DO NOT** convert the probability to logarithmic probability, otherwise you will fail the tests on Gradescope.\n",
    "\n",
    "In the autograder, we will also test your code against other `evidence_vectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gaussian_prob(x, para_tuple):\n",
    "    \"\"\"Compute the probability of a given x value\n",
    "\n",
    "    Args:\n",
    "        x (float): observation value\n",
    "        para_tuple (tuple): contains two elements, (mean, standard deviation)\n",
    "\n",
    "    Return:\n",
    "        Probability of seeing a value \"x\" in a Gaussian distribution.\n",
    "\n",
    "    Note:\n",
    "        We simplify the problem so you don't have to take care of integrals.\n",
    "        Theoretically speaking, the returned value is not a probability of x,\n",
    "        since the probability of any single value x from a continuous \n",
    "        distribution should be zero, instead of the number outputed here.\n",
    "        By definition, the Gaussian percentile of a given value \"x\"\n",
    "        is computed based on the \"area\" under the curve, from left-most to x. \n",
    "        The proability of getting value \"x\" is zero bcause a single value \"x\"\n",
    "        has zero width, however, the probability of a range of value can be\n",
    "        computed, for say, from \"x - 0.1\" to \"x + 0.1\".\n",
    "\n",
    "    \"\"\"\n",
    "    if list(para_tuple) == [None, None]:\n",
    "        return 0.0\n",
    "\n",
    "    mean, std = para_tuple\n",
    "    gaussian_percentile = (2 * np.pi * std**2)**-0.5 * \\\n",
    "                          np.exp(-(x - mean)**2 / (2 * std**2))\n",
    "    return gaussian_percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def viterbi(evidence_vector, states, prior_probs,\n",
    "            transition_probs, emission_paras):\n",
    "    \"\"\"Viterbi Algorithm to calculate the most likely states give the evidence.\n",
    "    Args:\n",
    "        evidence_vector (list): List of right hand Y-axis positions (interger).\n",
    "        states (list): List of all states in a word. No transition between words.\n",
    "                       example: ['B1', 'B2', 'B3', 'Bend', 'H1', 'H2', 'H3', 'Hend']\n",
    "        prior_probs (dict): prior distribution for each state.\n",
    "                            example: {'X1': 0.25,\n",
    "                                      'X2': 0.25,\n",
    "                                      'X3': 0.25,\n",
    "                                      'Xend': 0.25}\n",
    "        transition_probs (dict): dictionary representing transitions from each\n",
    "                                 state to every other valid state such as for the above \n",
    "                                 states, there won't be a transition from 'B1' to 'H1'\n",
    "        emission_paras (dict): parameters of Gaussian distribution \n",
    "                                from each state.\n",
    "    Return:\n",
    "        tuple of\n",
    "        ( A list of states the most likely explains the evidence,\n",
    "          probability this state sequence fits the evidence as a float )\n",
    "    Note:\n",
    "        You are required to use the function gaussian_prob to compute the\n",
    "        emission probabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: complete this function.\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    sequence = []\n",
    "    probability = 0.0\n",
    "\n",
    "    return sequence, probability\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.TestPart1b().test_viterbi_case1(part_1_a, viterbi)\n",
    "tests.TestPart1b().test_viterbi_case2(part_1_a, viterbi)\n",
    "tests.TestPart1b().test_viterbi_case3(part_1_a, viterbi)\n",
    "tests.TestPart1b().test_viterbi_realsample1(part_1_a, viterbi)\n",
    "tests.TestPart1b().test_viterbi_realsample2(part_1_a, viterbi)\n",
    "tests.TestPart1b().test_viterbi_realsample3(part_1_a, viterbi)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2a: Multidimensional Output Probabilities\n",
    "_[6 Points]_\n",
    "\n",
    "In Part 1a, we use only right-hand Y-axis coordinates as our solely feature, now we are going to use both hands. Since sign language is two handed, using features both to the right and left hands can increase the accuracy of our model when dealing with more complex sentences.\n",
    "\n",
    "Here you are given with the transition probabilities, and the means & standard deviations for emission probabilties of left-hand Y-axis locations, following the same procedure conducted in Part 1a.\n",
    "\n",
    "One thing to notice is, in Part 1, the `viterbi` function is tested against single words. In other words, the input evidence vector will not transit between different words. However, for Part 2, the input evidence vector can be either a single word, or a verb phrase such as \"BUY CAR\" and \"BUY HOUSE\". Adjust the probabilities in the image below to adapt to this fact. Note that consecutive words should be different.\n",
    "\n",
    "<img src=\"part_2_a_probs.png\" alt=\"2a_probs\">\n",
    "\n",
    "BUY | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 108.200 | 78.670 | 64.182\n",
    "Std | 17.314 | 1.886 | 5.573\n",
    "\n",
    "CAR | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 56.300 | 37.110 | 50.000\n",
    "Std | 10.659 | 4.306 | 7.826\n",
    "\n",
    "HOUSE | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 53.600 | 37.168 | 74.176\n",
    "Std | 7.392 | 8.875 | 8.347\n",
    "\n",
    "#### Functions to complete:\n",
    "1. `part_2_a()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def part_2_a():\n",
    "    \"\"\"Provide probabilities for the word HMMs outlined below.\n",
    "    Now, at each time frame you are given with 2 observations (right hand Y\n",
    "    position & left hand Y position). Use the result you derived in\n",
    "    part_1_a, accompany with the provided probability for left hand, create\n",
    "    a tuple of (right-y, left-y) to represent high-dimension transition & \n",
    "    emission probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "     # TODO: complete this function.\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    \"\"\"Word BUY\"\"\"\n",
    "    b_prior_probs = {\n",
    "        'B1': 0.,\n",
    "        'B2': 0.,\n",
    "        'B3': 0.,\n",
    "        'Bend': 0.,\n",
    "    }\n",
    "    # example: {'B1': {'B1' : (right-hand Y, left-hand Y), ... }\n",
    "    b_transition_probs = {\n",
    "        'B1': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0., 0.), 'Bend': (0., 0.)},\n",
    "        'B2': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0., 0.), 'Bend': (0., 0.)},\n",
    "        'B3': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0., 0.), 'Bend': (0., 0.)},\n",
    "        'Bend': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0., 0.), 'Bend': (0., 0.)},\n",
    "    }\n",
    "    # example: {'B1': [(right-mean, right-std), (left-mean, left-std)] ...}\n",
    "    b_emission_paras = {\n",
    "        'B1': [(None, None), (None, None)],\n",
    "        'B2': [(None, None), (None, None)],\n",
    "        'B3': [(None, None), (None, None)],\n",
    "        'Bend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    \"\"\"Word Car\"\"\"\n",
    "    c_prior_probs = {\n",
    "        'C1': 0.,\n",
    "        'C2': 0.,\n",
    "        'C3': 0.,\n",
    "        'Cend': 0.,\n",
    "    }\n",
    "    c_transition_probs = {\n",
    "        'C1': {'C1': (0., 0.), 'C2': (0., 0.), 'C3': (0., 0.), 'Cend': (0., 0.)},\n",
    "        'C2': {'C1': (0., 0.), 'C2': (0., 0.), 'C3': (0., 0.), 'Cend': (0., 0.)},\n",
    "        'C3': {'C1': (0., 0.), 'C2': (0., 0.), 'C3': (0., 0.), 'Cend': (0., 0.)},\n",
    "        'Cend': {'C1': (0., 0.), 'C2': (0., 0.), 'C3': (0., 0.), 'Cend': (0., 0.)},\n",
    "    }\n",
    "    c_emission_paras = {\n",
    "        'C1': [(None, None), (None, None)],\n",
    "        'C2': [(None, None), (None, None)],\n",
    "        'C3': [(None, None), (None, None)],\n",
    "        'Cend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    \"\"\"Word HOUSE\"\"\"\n",
    "    h_prior_probs = {\n",
    "        'H1': 0.,\n",
    "        'H2': 0.,\n",
    "        'H3': 0.,\n",
    "        'Hend': 0.,\n",
    "    }\n",
    "    h_transition_probs = {\n",
    "        'H1': {'H1': (0., 0.), 'H2': (0., 0.), 'H3': (0., 0.), 'Hend': (0., 0.)},\n",
    "        'H2': {'H1': (0., 0.), 'H2': (0., 0.), 'H3': (0., 0.), 'Hend': (0., 0.)},\n",
    "        'H3': {'H1': (0., 0.), 'H2': (0., 0.), 'H3': (0., 0.), 'Hend': (0., 0.)},\n",
    "        'Hend': {'H1': (0., 0.), 'H2': (0., 0.), 'H3': (0., 0.), 'Hend': (0., 0.)},\n",
    "    }\n",
    "    h_emission_paras = {\n",
    "        'H1': [(None, None), (None, None)],\n",
    "        'H2': [(None, None), (None, None)],\n",
    "        'H3': [(None, None), (None, None)],\n",
    "        'Hend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    return (b_prior_probs, b_transition_probs, b_emission_paras,\n",
    "            c_prior_probs, c_transition_probs, c_emission_paras,\n",
    "            h_prior_probs, h_transition_probs, h_emission_paras,)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.TestPart2a().test_prior(part_2_a)\n",
    "tests.TestPart2a().test_b_emission(part_2_a)\n",
    "tests.TestPart2a().test_c_emission(part_2_a)\n",
    "tests.TestPart2a().test_h_emission(part_2_a)\n",
    "tests.TestPart2a().test_b_transition(part_2_a)\n",
    "tests.TestPart2a().test_c_transition(part_2_a)\n",
    "tests.TestPart2a().test_h_transition(part_2_a)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b: Improving the Viterbi Trellis\n",
    "_[39 Points]_\n",
    "\n",
    "Modify the Viterbi Trellis function to allow multiple observed values (Y location of right and left hands) for a state. The return format should be identical to Part 1b.\n",
    "\n",
    "\n",
    "#### Functions to complete:\n",
    "1. `multidimensional_viterbi()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def multidimensional_viterbi(evidence_vector, states, prior_probs,\n",
    "                             transition_probs, emission_paras):\n",
    "    \"\"\"Decode the most likely word phrases generated by the evidence vector.\n",
    "    States, prior_probs, transition_probs, and emission_probs will now contain\n",
    "    all the words from part_2_a.\n",
    "    Evidence vector is a list of tuples where the first element of each tuple is the right \n",
    "    hand coordinate and the second element is the left hand coordinate.\n",
    "    \"\"\"\n",
    "    # TODO: complete this function.\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    sequence = []\n",
    "    probability = 0.0\n",
    "\n",
    "    return sequence, probability\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.TestPart2b().test_viterbi_case1(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_case2(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_case3(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_realsample1(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_realsample2(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_realsample3(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_phrase1(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_phrase2(part_2_a, multidimensional_viterbi)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def return_your_name():\n",
    "    \"\"\"Return your name\n",
    "    \"\"\"\n",
    "    # TODO: finish this\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONGRATULATIONS!**  You have just completed your final assignment for CS6601 Artificial Intelligence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONGRATULATIONS!**  You have just completed your final assignment for CS6601 Artificial Intelligence.\n",
    "\n",
    "\n",
    "### Bonus\n",
     "_[5 Points]_\n",
    "\n",
    "Note: All graphics are from Dr. Ploetz's 2005 Disseration [\"Advanced Stochastic Protein Sequence Analysis\"](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.667.139&rep=rep1&type=pdf)\n",
    "\n",
    "#### Description\n",
    "\n",
    "You might have noticed that the HMMs that you've constructed in this assignment are created and trained using data from only one user in a static environment. While these can be useful in practice, it is often the case that we want our HMMS to adapt to many different users and many different environments. For example, if we're reading hand positions from a video frame, what if the capture device is tilted? Our left and right hand position data will be affected, and our HMM could output a low probability for what in reality could be a perfect sign. How do we approach this problem?\n",
    "\n",
    "One solution is to collect lots of data from whatever scenario we find ourselves in and train an entirely new HMM. This is infeasible in many real-world applications, and is extremely data inefficient as we discard all data collected beforehand. A more practical solution is to collect a small amount of data for our new scenario, and use this data to adapt our previously trained HMM for use in this unfamiliar environment. One prevalent technique to apply this idea is called MLLR, or Maximum Likelihood Linear Regression, and involves transforming Gaussian parameters in an HMM based on new adaptation data. It is feasible in real applications as it only requires a small amount of adaptation data, and is data efficient in that we keep the information gained from our original training data. In this bonus, you'll adapt your constructed models to a new user.\n",
    "\n",
    "In the context of sign language and many others, when we adapt our model we don't want to change the transition probabilities, only the gaussian emission parameters of each state. Think of it as the signs themselves are not changing; simply the context in which we observe our data is changing. If we plotted all of our emission gaussians for all states, we might see something like this:\n",
    "\n",
    "<img src=\"bonus_graphics/sign_mixture.PNG\" alt=\"gaussian_plot\">\n",
    "\n",
    "In the scenario above with the tilted capture device, we would expect the general form of our model to stay the same with a slight transformation to fit the misaligned angle. Given a small amount of data from this tilted perspective, we would want to construct a transformation such that we can produce a HMM for this specific scenario. This is depicted in the graphic below:\n",
    "\n",
    "<img src=\"bonus_graphics/adapted_signs.PNG\" alt=\"gaussian_plot\">\n",
    "\n",
    "##### In this bonus we'll focus on creating a transformation matrix to change the means of each gaussian, not the variance.\n",
    "\n",
    "\n",
    "#### Procedure\n",
    "\n",
    "Below are three new data sequences for a new user in an unknown environment. Note that the data points in each state are provided, and there is no need for moving data points between states.\n",
    "\n",
    "Word | Frames | Observed sequence (R, L) | State1 | State2 | State3\n",
    "--- | --- | --- | --- | --- | --- \n",
    "BUY | 11 | (61,123), (61, 116), (59, 121), (65, 99), (73, 97), (75, 98), (79, 74), (79, 84), (79, 84), (74, 89), (68, 81) | (61,123), (61, 116), (59, 121) | (65, 99), (73, 97), (75, 98) | (79, 74), (79, 84), (79, 84), (74, 89), (68, 81) \n",
    "CAR | 8 | (44, 73), (53, 70), (62, 78), (64, 62), (66, 58), (59, 51), (61, 76), (58, 90)| (44, 73), (53, 70), (62, 78)| (64, 62), (66, 58), (59, 51)| (61, 76), (58, 90)\n",
    "HOUSE | 16 | (59, 65), (59, 68), (60, 69), (57, 70), (56, 64), (49, 59), (51, 57), (51, 51), (53, 51), (59, 59), (72, 79), (81, 82), (82, 89), (84, 90), (86, 90), (90, 93)| (59, 65), (59, 68), (60, 69), (57, 70), (56, 64)| (49, 59), (51, 57), (51, 51), (53, 51), (59, 59)| (72, 79), (81, 82), (82, 89), (84, 90), (86, 90), (90, 93)\n",
    "\n",
    "\n",
    "The original proposal of this technique is described in [C.J. Leggetter's 1995 paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.2050&rep=rep1&type=pdf), and we'll outline the steps here. Our objective is to construct a transformation matrix $W$ that we can apply to our existing means to produce the new parameters for our transformed HMM:\n",
    "\n",
    "<img src=\"bonus_graphics/adapted_means.PNG\" alt=\"gaussian_plot\">\n",
    "\n",
    "We can find this matrix W by the following equations:\n",
    "\n",
    "<img src=\"bonus_graphics/equations.PNG\" alt=\"gaussian_plot\">\n",
    "\n",
    "#### Variable Explanation:\n",
    "\n",
    "$R$: There are many derivations and considerations that we're simplifying in this section, and one of them is Regression Classes, denoted by $R$ in the above equations. A Regression Class is used if you want your adaptation data to only apply to a subset of your HMM, or only a certain collection of states. For this bonus, we consider all our states to be in the same Regression Class, and thus $\\delta$ will always be equal to one.\n",
    "\n",
    "$\\vec{x}_t$ : $\\vec{x}$ is the adaptation data vector, and $\\vec{x}_t$ represents the data collected in time-step $t$.\n",
    "\n",
    "$s_t$: $s_t$ represents the state that the sequence is currently in at time-step $t$.\n",
    "\n",
    "$\\mu_{ki}$: $\\mu_k$ represents the means of a particular state $k$, and $i$ refers to each dimension in the mean.  \n",
    "\n",
    "#### Functions to complete:\n",
    "\n",
    "1. `MLLR_results()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def MLLR_results():\n",
    "    \n",
    "    \"\"\"Complete the MLLR adaptation process with the new adaptation data and \n",
    "     return the new emission parameters for each state.\n",
    "    \"\"\"\n",
    "    # TODO: complete this function.\n",
    "\n",
    "\n",
    "    b_emission_paras = {\n",
    "        'B1': [(None, None), (None, None)],\n",
    "        'B2': [(None, None), (None, None)],\n",
    "        'B3': [(None, None), (None, None)],\n",
    "        'Bend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    c_emission_paras = {\n",
    "        'C1': [(None, None), (None, None)],\n",
    "        'C2': [(None, None), (None, None)],\n",
    "        'C3': [(None, None), (None, None)],\n",
    "        'Cend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    h_emission_paras = {\n",
    "        'H1': [(None, None), (None, None)],\n",
    "        'H2': [(None, None), (None, None)],\n",
    "        'H3': [(None, None), (None, None)],\n",
    "        'Hend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    return (b_emission_paras, \n",
    "            c_emission_paras, \n",
    "            h_emission_paras)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
